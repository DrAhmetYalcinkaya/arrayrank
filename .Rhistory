message(paste("Replaced", replaced_n, "values that are lower than the selected offset value of", offset, "with", strategy, "strategy"))
return(data)
}
#' \dontrun{
#' # Quantile normalization
#' norm_data <- multinorm(data = your_data, method = "quantile")
#'
#' # Between-array normalization
#' norm_data <- multinorm(data = your_data, method = "arrays")
#'
#' # Protein-based normalization
#' norm_data <- multinorm(data = your_data, method = "ig")
#' }
multinorm <- function(data, method = "quantile") {
data <- as.data.frame(data)
data[] <- lapply(data, as.numeric)
if (ncol(data) == 0 || nrow(data) == 0) {
stop("Data contains no valid numeric columns or rows.")
}
selected <- tolower(rownames(data)) %>%
grep("goatanti-huig", .) %>%
data[.,]
if (nrow(selected) == 0) {
selected <- tolower(rownames(data)) %>%
{data[grepl("igg", .) & grepl("100ng/ul", .), ]}
}
ortalamalar <- apply(selected, 2, mean)
beta <- median(unlist(selected))
logistic_trans <- Vectorize(function(x, b = beta, alt = 0.8, ust = 1.8) {
if (x < b/4) {
a = 0.009
return(1 / (1 + exp(-a * (x - b))))
} else {
a = 0.001
return(alt + (ust - alt) / (1 + exp(-a * (b - x))))
}
})
log_trans <- logistic_trans(ortalamalar)
binary <- ifelse(log_trans > 0.01, TRUE, FALSE)
if (sum(!binary) > 0) {
post_data <- data[, binary, drop = FALSE]
backup <- data[, !binary, drop = FALSE]
message("Extremely low Ig responses detected in: ", paste(colnames(data)[!binary], collapse = ", "),
"\nHighly suggested to exclude these indices from the data. Normalization will continue without altering these columns.")
} else {
post_data <- data
backup <- NULL
message("No columns identified as negative controls. Proceeding with normalization.")
}
if (method == "quantile") {
normed <- as.data.frame(round(limma::normalizeQuantiles(post_data), 1))
data[, binary] <- normed
output <- round(data, 1)
message("Normalized each column (observations) with limma-Quantile.")
} else if (method == "arrays") {
normed <- as.data.frame(round(limma::normalizeBetweenArrays(post_data), 1))
data[, binary] <- normed
output <- round(data, 1)
message("Normalized between arrays (Blocks or Huprot) with limma-BetweenArrays.")
} else if (method == "ig") {
df <- data
for (i in 1:ncol(df)) {
k <- ifelse(log_trans < 0.1, 1, log_trans)
df[, i] <- data[, i] * k[i]
output <- round(df, 1)
}
message("Normalized for Ig values.")
} else {
message("Please define normalization variables correctly.")
}
return(output)
}
#' @return A data frame with an additional column for protein names, ready for export to Excel or other formats.
#' @export
#'
#' @import dplyr
#'
#' @examples
#' \dontrun{
#' # Example usage of store.df function
#' data_to_store <- store.df(data = your_data)
#' }
store.df <- function(data) {
protein_names <- rownames(data)
output <- cbind(protein_names, data)
message("Storable dataframe created for export into Excel.")
return(output)
}
#'
#' @import dplyr
#'
#' @examples
#' \dontrun{
#' # Example usage of detect.hits function
#' ranked_proteins <- detect.hits(data = my_data,
#'                                controls = "Control",
#'                                examine = c("Treatment1", "Treatment2"))
#' }
detect.hits <- function(data, group_vector = NULL, controls, examine = NULL,
sdmean = 0.7, min_mean = 250,
fold_threshold = 10, absolute_threshold = 7000,
fold_shared = 1, abs_shared = 1) {
# Convert to a data frame if it's not already (handling tibbles)
if ("tbl_df" %in% class(data)) {
data <- as.data.frame(data)
}
# Attempt to convert the first row (excluding the first column) to numeric
first_row_numeric <- suppressWarnings(as.numeric(as.character(data[1, -1])))
is_first_row_numeric <- !any(is.na(first_row_numeric))
# If group_vector is provided, use it; otherwise, decide based on the first row content
if (!is.null(group_vector)) {
if (length(group_vector) != ncol(data) - 1) {
stop("The length of 'group_vector' must match the number of samples in the data (columns except the protein name column).")
}
cat("A group_vector has been provided.\nAnalysis will assume the first row contains array data.\n\n")
groups <- as.character(group_vector)
proteins <- as.character(data[, 1])
data <- data[, -1]
} else if (is_first_row_numeric) {
cat("The first row is numeric (array data?) and no group_vector has been provided.\nINFO: This function can accept groups as a character vector (group_vector = '')\nor as character entries in the first row of the dataset.\nPlease provide group info as such.\n")
stop()
} else {
message("The first row appears to contain group data, analyzing based on these groups")
groups <- as.character(data[1, -1])
proteins <- as.character(data[-c(1), 1])
data <- data[-c(1), -1]
}
# Convert column data to numeric and define proteins as row names
data[] <- lapply(data, as.numeric)
rownames(data) <- proteins
print(table(groups))
# Identify the control group indices
control_indices <- which(groups == controls)
if (length(control_indices) == 0) {
stop("The specified control group was not found in the group annotations.")
}
# If no specific non-control groups are provided, use all except the control group
if (is.null(examine)) {
non_control_indices <- which(groups != controls)
} else {
non_control_indices <- which(groups %in% examine)
}
if (length(non_control_indices) == 0) {
stop("No valid non-control groups were found based on your criteria.")
}
# Check and print out groups being analyzed
message(paste("Selected control group:", controls))
message(paste("Selected analysis group:", paste(unique(groups[non_control_indices]), collapse=", ")))
# Check if the standard deviation-to-mean ratio is greater than sdmean value
variation <- function(row, ratio) {
sd_to_mean_ratio <- sd(row) / mean(row)
return(sd_to_mean_ratio > ratio)
}
# Filter rows based on variance in the data
filter_variance <- apply(as.matrix(data[, non_control_indices]), 1, variation, sdmean)
edf2 <- data[filter_variance, ]
proteins <- proteins[filter_variance]  # adjust the 'proteins' list with the same filter
message(paste("Filtered data based on variance:", nrow(edf2)))
# Filter rows based on the mean value of each row in the non-control data
filter_minmean <- apply(edf2[, non_control_indices], 1, function(row) mean(row) > min_mean)
edf3 <- edf2[filter_minmean, ]
proteins <- proteins[filter_minmean]
message(paste("Filtered data based on mean value:", nrow(edf3)))
# Calculate the mean value for controls while excluding the highest value
edf3$ControlMean <- apply(edf3[, control_indices], 1, function(row) mean(row[row != max(row)]))
# Exclude proteins where controls have higher values compared to the max value in non-control samples
filter_greatercontrols <- edf3$ControlMean < apply(edf3[, non_control_indices], 1, max)
edf4 <- edf3[filter_greatercontrols, ]
proteins <- proteins[filter_greatercontrols]
message(paste("Filtered data based on greater-than-controls check:", nrow(edf4)))
# Filter based on fold change
filter_folddif <- rowSums(edf4[, non_control_indices] > fold_threshold * edf4$ControlMean) > (fold_shared - 1)
edf5 <- edf4[filter_folddif, ]
proteins <- proteins[filter_folddif]
message(paste("Filtered data based on fold difference:", nrow(edf5)))
# Filter based on absolute difference
filter_absdif <- rowSums(edf5[, non_control_indices] > absolute_threshold) > (abs_shared - 1)
edf6 <- edf5[filter_absdif, ]
proteins <- proteins[filter_absdif]
message(paste("Filtered data based on absolute difference:", nrow(edf6)))
# Extract absolute values of non-control samples
abs_values_non_controls <- edf6[, non_control_indices]
# Calculate fold change for each protein
fold_changes <- abs_values_non_controls / edf6$ControlMean
# Number of hits
number_of_hits <- rowSums((fold_changes > fold_threshold) & (abs_values_non_controls > absolute_threshold))
# Base ranking score for each non-control
fold_changes_with_abslog <- (fold_changes * log10(abs_values_non_controls))
# Order for raw foldchange and basescore data -- separately
fold_change_values <- t(apply(fold_changes, 1, function(row) row[order(-row)]))
score_foldchange_and_log10 <- t(apply(fold_changes_with_abslog, 1, function(row) row[order(-row)]))
# Sum the scores for each non-control to create final ranking score
rankingscore <- (rowSums(score_foldchange_and_log10) * number_of_hits * log10(edf6$ControlMean))
message("Rank scores calculated")
# Add ranking score, highest fold change, number of hits, and BDmean to the dataframe
abs_values_non_controls$highest_fold_change <- fold_change_values[, 1]
abs_values_non_controls$potential_hits <- number_of_hits
abs_values_non_controls$control_mean <- edf6$ControlMean
abs_values_non_controls$rankingscore <- rankingscore
message("Supportive info added.")
# Add a rank column to the dataframe (convenience)
abs_values_non_controls$rank <- rank(-abs_values_non_controls$rankingscore)
# Match the length of 'Proteins' to the filtered data
if (length(proteins) != nrow(abs_values_non_controls)) {
stop("Mismatch in the number of rows after final filtering. Perhaps check the data for format or structure?")
}
# Combine results with protein and group information
results <- data.frame(proteins, abs_values_non_controls, check.names = FALSE)
ranked_prots <- results[order(results$rank), ]
return(ranked_prots)
}
# 1. collect gpr data and make dataset
raw_data <- read.gpr(bgcorrect = T, fdata = "median")
wide_df <- extraction(raw_data, array_type = "chambered", format = "wide")
wide_df <- extraction(raw_data, array_type = "chambered", format = "wide")
library(dplyr)
wide_df <- extraction(raw_data, array_type = "chambered", format = "wide")
# 1b. identify discordant duplicates in data (to cross-check with ultimate output)
discordants <- discordant(raw_data, array_type = "chambered", fold = 2, abs = 1000)
# 2. data correction
corr_df <- replace.low(wide_df, offset = 10)
qnorm_df <- multinorm(corr_df, method= "ig")
# 3. storage and backup
qstore_df <- store.df(qnorm_df)
# 4. read data from backup file
q_data <- readxl::read_xlsx(choose.files())
# 5. read group info from excel (if you want to provide a vector defining the sample groups)
groups <- readxl::read_xlsx(choose.files())
groupsv <- t(groups[,2])
# 6. detect proteins with hits and rank them (in this example: the groups, BD and SSc, have been provided as a vector)
q_result1 <- detect.hits(q_data, controls = "BD", group_vector = groupsv, examine = "Pan", sdmean = 0.5,
fold_threshold = 5, absolute_threshold = 5000)
# 1. collect gpr data and make dataset
raw_data <- read.gpr(bgcorrect = T, fdata = "median")
wide_df <- extraction(raw_data, array_type = "huprot", format = "wide")
# 2. data correction
corr_df <- replace.low(wide_df, offset = 10)
qnorm_df <- multinorm(corr_df, method= "ig")
# 3. storage and backup
qstore_df <- store.df(qnorm_df)
View(qstore_df)
View(qstore_df)
library(arrayrank)
# 1. collect gpr data and make dataset
raw_data <- read.gpr(bgcorrect = T, fdata = "median")
wide_df <- extraction(raw_data, array_type = "chambered", format = "wide")
View(wide_df)
wide_df <- extraction(raw_data, array_type = "huprot", format = "wide")
View(wide_df)
# 1. collect gpr data and make dataset
raw_data <- read.gpr(bgcorrect = T, fdata = "median")
wide_df <- extraction(raw_data, array_type = "huprot", format = "wide")
library(devtools)
remove.packages("arrayrank")
detach("package:arrayrank", unload = TRUE)
devtools::install_github("DrAhmetYalcinkaya/arrayrank")
devtools::install_github("DrAhmetYalcinkaya/arrayrank")
wide_df2 <- extraction(raw_data, array_type = "huprot", format = "wide")
library(arrayrank)
wide_df2 <- extraction(raw_data, array_type = "huprot", format = "wide")
wide_df2 <- extraction(raw_data, array_type = "chambered", format = "wide")
View(wide_df2)
devtools::install_github("DrAhmetYalcinkaya/arrayrank")
# 1. collect gpr data and make dataset
raw_data <- read.gpr(bgcorrect = T, fdata = "median")
wide_df <- extraction(raw_data, array_type = "chambered", format = "wide")
View(wide_df)
View(wide_df2)
View(wide_df)
library(arrayrank)
# 1. collect gpr data and make dataset
raw_data <- read.gpr(bgcorrect = T, fdata = "median")
wide_df <- extraction(raw_data, array_type = "chambered", format = "wide")
# 1b. identify discordant duplicates in data (to cross-check with ultimate output)
discordants <- discordant(raw_data, array_type = "chambered", fold = 2, abs = 1000)
# 2. data correction
corr_df <- replace.low(wide_df, offset = 10)
qnorm_df <- multinorm(corr_df, method= "ig")
View(qnorm_df)
max(qnorm_df)
# 3. storage and backup
qstore_df <- store.df(qnorm_df)
writexl::write_xlsx(qstore_df, "Sigmoid_normed_casanova.xlsx")
# 4. read data from backup file
q_data <- readxl::read_xlsx(choose.files())
# 5. read group info from excel (if you want to provide a vector defining the sample groups)
groups <- readxl::read_xlsx(choose.files())
View(groups)
groupsv <- t(groups[,2]) ### note: read/create/edit the character vector based on your own requirements!!!
# 6. detect proteins with hits and rank them (in this example: the groups, BD and SSc, have been provided as a vector)
q_result1 <- detect.hits(q_data, controls = "BD", group_vector = groupsv, examine = "Pan", sdmean = 0.5,
fold_threshold = 5, absolute_threshold = 5000)
# 6. detect proteins with hits and rank them (in this example: the groups, BD and SSc, have been provided as a vector)
q_result1 <- detect.hits(q_data, controls = "BD", group_vector = groupsv, sdmean = 0.5,
fold_threshold = 5, absolute_threshold = 5000)
# 6. detect proteins with hits and rank them (in this example: the groups, BD and SSc, have been provided as a vector)
q_result <- detect.hits(q_data, controls = "BD", group_vector = groupsv, sdmean = 0.5,
fold_threshold = 5, absolute_threshold = 5000)
writexl::write_xlsx(q_result, "Hits_sigmoidnormed_casanova.xlsx")
# 6. detect proteins with hits and rank them (in this example: the groups, BD and SSc, have been provided as a vector)
q_result <- detect.hits(q_data, controls = "BD", group_vector = groupsv, sdmean = 0.5,
fold_threshold = 10, absolute_threshold = 5000)
View(q_result)
library(arrayrank)
# 1. collect gpr data and make dataset
raw_data <- read.gpr(bgcorrect = T, fdata = "median")
wide_df <- extraction(raw_data, array_type = "huprot", format = "wide")
View(wide_df)
# 2. data correction
corr_df <- replace.low(wide_df, offset = 10)
View(corr_df)
View(wide_df)
View(corr_df)
min(wide_df)
which(min(wide_df))
which(wide_df == min(wide_df))
which(wide_df == min(wide_df), indices = T)
which(wide_df == min(wide_df), index = T)
?which()
which(wide_df == min(wide_df), ind = T)
which(wide_df == min(wide_df), arr.ind = T)
# 4. read data from backup file
q_data <- readxl::read_xlsx(choose.files())
# 4. read data from backup file
q_data <- readxl::read_xlsx(choose.files())
View(q_data)
# 4. read data from backup file
q_data <- readxl::read_xlsx(choose.files())
View(q_data)
# 4. read data from backup file
q_data <- readxl::read_xlsx(choose.files())
View(q_data)
# 4. read data from backup file
q_data <- readxl::read_xlsx(choose.files())
View(q_data)
# 6. detect proteins with hits and rank them (in this example: the groups have been provided as a vector)
q_result <- detect.hits(q_data, controls = "BD",
examine = "SSc", sdmean = 0.5, fold_threshold = 10, absolute_threshold = 7000)
library(arrayrank)
# 6. detect proteins with hits and rank them (in this example: the groups have been provided as a vector)
q_result <- detect.hits(q_data, controls = "BD",
examine = "SSc", sdmean = 0.5, fold_threshold = 10, absolute_threshold = 7000)
View(q_result)
# 6. detect proteins with hits and rank them (in this example: the groups have been provided as a vector)
q_result_2k <- detect.hits(q_data, controls = "BD",
examine = "SSc", sdmean = 0.5, fold_threshold = 10, absolute_threshold = 2000)
View(q_result_2k)
View(q_result)
View(q_result_2k)
View(q_result)
View(q_result)
View(q_result)
View(q_result_2k)
# 6. detect proteins with hits and rank them (in this example: the groups have been provided as a vector)
q_result_2k2 <- detect.hits(q_data, controls = "BD",
examine = "SSc", sdmean = 0.5, fold_threshold = 4, absolute_threshold = 2000)
View(q_result_2k2)
View(q_result_2k2)
# 6. detect proteins with hits and rank them (in this example: the groups have been provided as a vector)
q_result_2k2 <- detect.hits(q_data, controls = "BD",
examine = "SSc", sdmean = 0.5, fold_threshold = 2, absolute_threshold = 1000)
View(q_result_2k2)
library(arrayrank)
# 1. collect gpr data and make dataset
raw_data <- read.gpr(bgcorrect = T, fdata = "median")
wide_df <- extraction(raw_data, array_type = "chambered", format = "wide")
View(wide_df)
# 2. data correction
corr_df <- replace.low(wide_df, offset = 10)
qnorm_df <- multinorm(corr_df, method= "ig")
data <- corr_df
if (ncol(data) == 0 || nrow(data) == 0) {
stop("Data contains no valid numeric columns or rows.")
}
selected <- tolower(rownames(data)) %>%
grep("goatanti-huig", .) %>%
data[.,]
#' \dontrun{
#' # Quantile normalization
#' norm_data <- multinorm(data = your_data, method = "quantile")
#'
#' # Between-array normalization
#' norm_data <- multinorm(data = your_data, method = "arrays")
#'
#' # Protein-based normalization
#' norm_data <- multinorm(data = your_data, method = "ig")
#' }
library(dplyr)
selected <- tolower(rownames(data)) %>%
grep("goatanti-huig", .) %>%
data[.,]
View(selected)
View(corr_df)
if (nrow(selected) == 0) {
selected <- tolower(rownames(data)) %>%
{data[grepl("igg", .) & grepl("100ng/ul", .), ]}
}
selected <- tolower(rownames(data)) %>%
grep("hu", .) %>%
data[.,]
View(selected)
selected <- tolower(rownames(data)) %>%
grep("hu IgG", .) %>%
data[.,]
View(selected)
selected <- tolower(rownames(data)) %>%
grep("hu igg", .) %>%
data[.,]
selected <- tolower(rownames(data)) %>%
grep("hu igg", .) %>%
data[.,]
selected <- tolower(rownames(data)) %>%
grep("hu", .) %>%
data[.,]
View(selected)
selected <- tolower(rownames(data)) %>%
grep("hu igg", .) %>%
data[.,]
View(selected)
selected <- tolower(rownames(data)) %>%
grep("igg", .) %>%
data[.,]
View(selected)
selected <- tolower(rownames(data)) %>%
grep("anti-hu igg", .) %>%
data[.,]
if (nrow(selected) == 0) {
selected <- tolower(rownames(data)) %>%
{data[grepl("igg", .) & grepl("100ng/ul", .), ]}
}
#' \dontrun{
#' # Quantile normalization
#' norm_data <- multinorm(data = your_data, method = "quantile")
#'
#' # Between-array normalization
#' norm_data <- multinorm(data = your_data, method = "arrays")
#'
#' # Protein-based normalization
#' norm_data <- multinorm(data = your_data, method = "ig")
#' }
multinorm <- function(data, method = "quantile") {
data <- as.data.frame(data)
data[] <- lapply(data, as.numeric)
if (ncol(data) == 0 || nrow(data) == 0) {
stop("Data contains no valid numeric columns or rows.")
}
selected <- tolower(rownames(data)) %>%
grep("anti-hu igg", .) %>%
data[.,]
if (nrow(selected) == 0) {
selected <- tolower(rownames(data)) %>%
{data[grepl("igg", .) & grepl("100ng/ul", .), ]}
}
ortalamalar <- apply(selected, 2, mean)
beta <- median(unlist(selected))
logistic_trans <- Vectorize(function(x, b = beta, alt = 0.8, ust = 1.8) {
if (x < b/4) {
a = 0.009
return(1 / (1 + exp(-a * (x - b))))
} else {
a = 0.001
return(alt + (ust - alt) / (1 + exp(-a * (b - x))))
}
})
log_trans <- logistic_trans(ortalamalar)
binary <- ifelse(log_trans > 0.01, TRUE, FALSE)
if (sum(!binary) > 0) {
post_data <- data[, binary, drop = FALSE]
backup <- data[, !binary, drop = FALSE]
message("Extremely low Ig responses detected in: ", paste(colnames(data)[!binary], collapse = ", "),
"\nHighly suggested to exclude these indices from the data. Normalization will continue without altering these columns.")
} else {
post_data <- data
backup <- NULL
message("No columns identified as negative controls. Proceeding with normalization.")
}
if (method == "quantile") {
normed <- as.data.frame(round(limma::normalizeQuantiles(post_data), 1))
data[, binary] <- normed
output <- round(data, 1)
message("Normalized each column (observations) with limma-Quantile.")
} else if (method == "arrays") {
normed <- as.data.frame(round(limma::normalizeBetweenArrays(post_data), 1))
data[, binary] <- normed
output <- round(data, 1)
message("Normalized between arrays (Blocks or Huprot) with limma-BetweenArrays.")
} else if (method == "ig") {
df <- data
for (i in 1:ncol(df)) {
k <- ifelse(log_trans < 0.1, 1, log_trans)
df[, i] <- data[, i] * k[i]
output <- round(df, 1)
}
message("Normalized for Ig values.")
} else {
message("Please define normalization variables correctly.")
}
return(output)
}
qnorm_df <- multinorm(corr_df, method= "ig")
View(qnorm_df)
max(qnorm_df)
# 3. storage and backup
qstore_df <- store.df(qnorm_df)
writexl::write_xlsx(qstore_df, "new_array_output.xlsx")
selected <- tolower(rownames(data)) %>%
grep("anti", .) %>%
data[.,]
View(selected)
selected <- tolower(rownames(data)) %>%
grep("anti-hu igg", .) %>%
data[.,]
