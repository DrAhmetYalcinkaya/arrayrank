df <- replace.low(orig_df, offset = 10)
dfs <- store.df(df)
writexl::write_xlsx(dfs, "non.xlsx")
df_qnorm <- multinorm(df, method= "quantile")
df_qstore <- store.df(df_qnorm)
writexl::write_xlsx(df_qstore, "normed.xlsx")
which(rownames(df) == "Anti-human IgG 1.5625ng/ul")
df_vnorm <- multinorm(df, method = "protein", protein = 1198)
df_vstore <- store.df(df_vnorm)
writexl::write_xlsx(df_vstore, "var_normed.xlsx")
q_data <- readxl::read_xlsx(choose.files())
groups <- read_xlsx(choose.files())
groups <- groups[1,-1]
q_result <- detect.hits(q_data, controls = "BD", group_vector = groups, examine = "SSc", sdmean = 0.7,
fold_threshold = 50, absolute_threshold = 8000)
q_result <- detect.hits(q_data, controls = "BD", group_vector = groups, examine = "SSc", sdmean = 0.7,
fold_threshold = 10, absolute_threshold = 8000)
View(q_result)
remove.packages("arrayrank")
devtools::install_github("DrAhmetYalcinkaya/arrayrank")
library(arrayrank)
files <- read.gpr()
devtools::install_github("DrAhmetYalcinkaya/arrayrank")
BiocManager::install("cluster")
install.packages("ropls")
library(arrayrank)
files <- read.gpr()
bg_subbed <- subtract.bg(files)
long_format <- extraction(bg_subbed)
orig_df <- make.df(long_format, "huprot")
df <- replace.low(orig_df, offset = 10)
dfs <- store.df(df)
df_qnorm <- multinorm(df, method= "quantile")
df_qstore <- store.df(df_qnorm)
writexl::write_xlsx(df_qstore, "normed.xlsx")
library(readxl)
q_data <- readxl::read_xlsx(choose.files())
q_data <- readxl::read_xlsx(choose.files())
groups <- read_xlsx(choose.files())
View(q_data)
View(orig_df)
View(q_data)
View(orig_df)
q_data <- readxl::read_xlsx(choose.files())
View(groups)
groups <- groups[1,-1]
View(groups)
q_result <- detect.hits(q_data, controls = "BD", group_vector = groups, examine = "SSc", sdmean = 0.7,
fold_threshold = 10, absolute_threshold = 8000)
View(q_result)
library(arrayrank)
library(readxl)
files <- read.gpr()
bg_subbed <- subtract.bg(files)
long_format <- extraction(bg_subbed)
orig_df <- make.df(long_format, "chambered")
df <- replace.low(orig_df, offset = 10)
df_qnorm <- multinorm(df, method= "quantile")
df_qstore <- store.df(df_qnorm)
writexl::write_xlsx(df_qstore, "protSgroup.xlsx")
orig_df <- make.df(long_format, "chambered")
df <- replace.low(orig_df, offset = 10)
View(df)
files <- read.gpr()
bg_subbed <- subtract.bg(files)
long_format <- extraction(bg_subbed)
orig_df <- make.df(long_format, "chambered")
df <- replace.low(orig_df, offset = 10)
df_qnorm <- multinorm(df, method= "quantile")
df_qstore <- store.df(df_qnorm)
writexl::write_xlsx(df_qstore, "protSgroup.xlsx")
files <- read.gpr()
library(arrayrank)
library(readxl)
files <- read.gpr()
# Load necessary library
library(data.table)
# Specify the directory containing the .gpr files
directory <- choose.dir()
# Get a list of all .gpr files in the directory
gpr_files <- list.files(directory, pattern = "\\.gpr$", full.names = TRUE)
# Specify the directory containing the .gpr files
directory <- choose.dir()
# Get a list of all .gpr files in the directory
gpr_files <- list.files(directory, pattern = "\\.gpr$", full.names = TRUE)
# Specify the target cells (row and column) - A9 and A12
target_cells <- list(c(9, 1), c(12, 1))  # A9 corresponds to row 9, column 1; A12 to row 12, column 1
# Function to remove content after '=' in specified cells
remove_content_after_equal <- function(file) {
# Read the file into a data table
data <- fread(file, header = FALSE, sep = "\t", stringsAsFactors = FALSE)
# Apply the modification to each specified cell
for (cell in target_cells) {
row <- cell[1]
col <- cell[2]
if (row <= nrow(data) && col <= ncol(data)) {
cell_value <- data[row, col, with = FALSE][[1]]
if (grepl("=", cell_value)) {
data[row, col] <- sub("=.*", "=", cell_value)
}
}
}
# Write the modified data back to the file
fwrite(data, file, sep = "\t", col.names = FALSE)
}
# Apply the function to all .gpr files
lapply(gpr_files, remove_content_after_equal)
# Apply the function to all .gpr files
lapply(gpr_files, remove_content_after_equal)
# Load necessary library
library(data.table)
# Specify the directory containing the .gpr files
input_directory <- choose.dir()
# Specify the directory to save the modified files
output_directory <- choose.dir()
# Create the output directory if it doesn't exist
if (!dir.exists(output_directory)) {
dir.create(output_directory)
}
# Get a list of all .gpr files in the input directory
gpr_files <- list.files(input_directory, pattern = "\\.gpr$", full.names = TRUE)
# Specify the target cells (row and column) - A9 and A12
target_cells <- list(c(9, 1), c(12, 1))  # A9 corresponds to row 9, column 1; A12 to row 12, column 1
# Function to remove content after '=' in specified cells
remove_content_after_equal <- function(file) {
# Read the file into a data table
data <- fread(file, header = FALSE, sep = "\t", stringsAsFactors = FALSE, quote="")
# Apply the modification to each specified cell
for (cell in target_cells) {
row <- cell[1]
col <- cell[2]
if (row <= nrow(data) && col <= ncol(data)) {
cell_value <- as.character(data[row, col, with = FALSE][[1]])
if (grepl("=", cell_value)) {
# Modify the cell value, keeping everything before the '=' sign
data[row, col] <- sub("=.*", "=", cell_value)
}
}
}
# Construct the new file path in the output directory
output_file <- file.path(output_directory, basename(file))
# Write the modified data to the new file
fwrite(data, output_file, sep = "\t", col.names = FALSE, quote=FALSE)
}
# Apply the function to all .gpr files
lapply(gpr_files, remove_content_after_equal)
warnings()
# Get a list of all .gpr files in the input directory
gpr_files <- list.files(input_directory, pattern = "\\.gpr$", full.names = TRUE)
# Specify the target cells (row and column) - A9 and A12
target_cells <- list(c(9, 1), c(12, 1))  # A9 corresponds to row 9, column 1; A12 to row 12, column 1
# Function to remove content after '=' in specified cells
remove_content_after_equal <- function(file) {
# Read the file into a data table, skipping metadata lines
data <- fread(file, header = FALSE, sep = "\t", stringsAsFactors = FALSE,
fill = TRUE, comment.char = "")
# Check if there is metadata at the top and find where the table starts
metadata_end <- which(grepl("^Block", data[[1]]))[1] - 1
if (is.na(metadata_end)) {
stop("Could not find the start of the data table. Please check the file structure.")
}
# Extract only the tabular data (assuming it's after the metadata)
table_data <- data[(metadata_end + 1):nrow(data),]
# Apply the modification to each specified cell in the tabular data
for (cell in target_cells) {
row <- cell[1]
col <- cell[2]
if (row <= nrow(table_data) && col <= ncol(table_data)) {
cell_value <- as.character(table_data[row, col, with = FALSE][[1]])
if (grepl("=", cell_value)) {
# Modify the cell value, keeping everything before the '=' sign
table_data[row, col] <- sub("=.*", "=", cell_value)
}
}
}
# Combine metadata and table_data back into one data table
modified_data <- rbindlist(list(data[1:metadata_end,], table_data), use.names = FALSE, fill = TRUE)
# Construct the new file path in the output directory
output_file <- file.path(output_directory, basename(file))
# Write the modified data to the new file
fwrite(modified_data, output_file, sep = "\t", col.names = FALSE, quote=FALSE)
}
# Apply the function to all .gpr files
lapply(gpr_files, remove_content_after_equal)
# Load necessary library
library(data.table)
# Specify the directory containing the .gpr files
input_directory <- choose.dir()
# Specify the directory to save the modified files
output_directory <- choose.dir()
# Create the output directory if it doesn't exist
if (!dir.exists(output_directory)) {
dir.create(output_directory)
}
# Get a list of all .gpr files in the input directory
gpr_files <- list.files(input_directory, pattern = "\\.gpr$", full.names = TRUE)
# Function to remove content after '=' for specific keys
remove_content_after_equal <- function(file) {
# Read all lines from the file
lines <- readLines(file)
# Identify lines containing "ImageFiles=" or "JpegImage="
lines <- gsub("ImageFiles=.*", "ImageFiles=", lines)
lines <- gsub("JpegImage=.*", "JpegImage=", lines)
# Construct the new file path in the output directory
output_file <- file.path(output_directory, basename(file))
# Write the modified lines to the new file
writeLines(lines, output_file)
}
# Apply the function to all .gpr files
lapply(gpr_files, remove_content_after_equal)
# Create the output directory if it doesn't exist
if (!dir.exists(output_directory)) {
dir.create(output_directory)
}
# Get a list of all .gpr files in the input directory
gpr_files <- list.files(input_directory, pattern = "\\.gpr$", full.names = TRUE)
# Function to remove content after '=' for specific keys
remove_content_after_equal <- function(file) {
# Read all lines from the file using readLines with UTF-8 encoding
lines <- readLines(file, encoding = "UTF-8")
# Replace content after "=" for the specified fields
lines <- gsub("ImageFiles=.*", "ImageFiles=", lines, perl = TRUE)
lines <- gsub("JpegImage=.*", "JpegImage=", lines, perl = TRUE)
# Construct the new file path in the output directory
output_file <- file.path(output_directory, basename(file))
# Write the modified lines to the new file with UTF-8 encoding
writeLines(lines, output_file, useBytes = TRUE)
}
# Apply the function to all .gpr files
lapply(gpr_files, remove_content_after_equal)
# Create the output directory if it doesn't exist
if (!dir.exists(output_directory)) {
dir.create(output_directory)
}
# Get a list of all .gpr files in the input directory
gpr_files <- list.files(input_directory, pattern = "\\.gpr$", full.names = TRUE)
# Function to remove content after '=' for specific keys
remove_content_after_equal <- function(file) {
# Read all lines from the file, trying to fix any encoding issues
lines <- readLines(file, warn = FALSE, encoding = "latin1")
# Convert the lines to UTF-8 encoding, skipping invalid characters
lines <- iconv(lines, from = "latin1", to = "UTF-8", sub = "")
# Replace content after "=" for the specified fields
lines <- gsub("ImageFiles=.*", "ImageFiles=", lines)
lines <- gsub("JpegImage=.*", "JpegImage=", lines)
# Construct the new file path in the output directory
output_file <- file.path(output_directory, basename(file))
# Write the modified lines to the new file
writeLines(lines, output_file)
}
# Apply the function to all .gpr files
lapply(gpr_files, remove_content_after_equal)
files <- read.gpr()
bg_subbed <- subtract.bg(files)
long_format <- extraction(bg_subbed)
orig_df <- make.df(long_format, "huprot")
df <- replace.low(orig_df, offset = 10)
View(df)
View(long_format)
View(files)
View(files[["targets"]])
View(files[["genes"]])
View(long_format)
detach("package:arrayrank", unload = TRUE)
#' @export
#'
#' @examples
#' \dontrun{
#' # Example usage for chambered/segmented arrays
#' processed_data <- make.df(data = your_data, array_type = "chambered")
#'
#' # Example usage for huprot arrays
#' processed_data <- make.df(data = your_data, array_type = "huprot")
#' }
make.df <- function(data, array_type){
# Convert data to data.table format
df <- data.table::setDT(data)
# Validate array_type parameter
if (!(array_type %in% c("chambered", "segmented", "huprot"))) {
stop("Invalid array_type. Please specify 'chambered', 'segmented', or 'huprot'.")
}
# Define required columns based on array type
required_columns <- if (array_type %in% c("chambered", "segmented")) {
c("array", "Block", "Name", "value")
} else {
c("array", "Name", "value")
}
# Check if the data contains the required columns
if (!all(required_columns %in% colnames(df))) {
stop(paste("Data must contain the following columns:", paste(required_columns, collapse = ", ")))
}
if (array_type == "chambered" || array_type == "segmented") {
long_result <- df[, .(Mvalue = mean(.SD$value, na.rm = TRUE)), by = .(array, Block, Name)]
wide_result <- tidyr::pivot_wider(long_result, names_from = Name, values_from = Mvalue)
message("Data calculated/arranged for chambered/segmented arrays")
transposed_result <- as.data.frame(t(wide_result))
array <- paste0("Arr", sapply(basename(transposed_result[1,]), function(x) gsub("[^0-9]","", x)))
new_colname <- paste0(array, "Block", transposed_result[2,], sep="-")
corrected_transposed_result <- transposed_result[-c(1,2),]
colnames(corrected_transposed_result) <- new_colname
numeric_df <- as.data.frame(lapply(corrected_transposed_result, as.numeric))
numeric_df <- as.data.frame(apply(numeric_df, 2, function(x) round(x, 2)))
rownames(numeric_df) <- rownames(corrected_transposed_result)
} else if (array_type == "huprot") {
long_result <- df[, .(Mvalue = mean(.SD$value, na.rm = TRUE)), by = .(array, Name)]
wide_result <- tidyr::pivot_wider(long_result, names_from = Name, values_from = Mvalue)
message("Data calculated/arranged for huprot arrays")
transposed_result <- as.data.frame(t(wide_result))
array <- paste0("Arr", sapply(basename(transposed_result[1,]), function(x) gsub("[^0-9]","", x)))
new_colname <- array
corrected_transposed_result <- transposed_result[-1,]
colnames(corrected_transposed_result) <- new_colname
numeric_df <- as.data.frame(lapply(corrected_transposed_result, as.numeric))
numeric_df <- as.data.frame(apply(numeric_df, 2, function(x) round(x, 2)))
rownames(numeric_df) <- rownames(corrected_transposed_result)
} else {
stop("Please define array type. Supports 'chambered', 'segmented', or 'huprot'")
}
if (nrow(numeric_df) == 0) {
warning("The resulting data frame is empty after processing.")
}
return(numeric_df)
}
orig_df <- make.df(long_format, "huprot")
View(orig_df)
library(arrayrank)
files <- read.gpr()
bg_subbed <- subtract.bg(files)
long_format <- extraction(bg_subbed)
#' @export
#'
#' @examples
#' \dontrun{
#' # Example usage for chambered/segmented arrays
#' processed_data <- make.df(data = your_data, array_type = "chambered")
#'
#' # Example usage for huprot arrays
#' processed_data <- make.df(data = your_data, array_type = "huprot")
#' }
make.df2 <- function(data, array_type){
# Convert data to data.table format
df <- data.table::setDT(data)
# Validate array_type parameter
if (!(array_type %in% c("chambered", "segmented", "huprot"))) {
stop("Invalid array_type. Please specify 'chambered', 'segmented', or 'huprot'.")
}
# Define required columns based on array type
required_columns <- if (array_type %in% c("chambered", "segmented")) {
c("array", "Block", "Name", "value")
} else {
c("array", "Name", "value")
}
# Check if the data contains the required columns
if (!all(required_columns %in% colnames(df))) {
stop(paste("Data must contain the following columns:", paste(required_columns, collapse = ", ")))
}
if (array_type == "chambered" || array_type == "segmented") {
long_result <- df[, .(Mvalue = mean(.SD$value, na.rm = TRUE)), by = .(array, Block, Name)]
wide_result <- tidyr::pivot_wider(long_result, names_from = Name, values_from = Mvalue)
message("Data calculated/arranged for chambered/segmented arrays")
transposed_result <- as.data.frame(t(wide_result))
array <- paste0("Arr", sapply(basename(transposed_result[1,]), function(x) gsub("[^0-9]","", x)))
new_colname <- paste0(array, "Block", transposed_result[2,], sep="-")
corrected_transposed_result <- transposed_result[-c(1,2),]
colnames(corrected_transposed_result) <- new_colname
numeric_df <- as.data.frame(lapply(corrected_transposed_result, as.numeric))
numeric_df <- as.data.frame(apply(numeric_df, 2, function(x) round(x, 2)))
rownames(numeric_df) <- rownames(corrected_transposed_result)
} else if (array_type == "huprot") {
long_result <- df[, .(Mvalue = mean(.SD$value, na.rm = TRUE)), by = .(array, Name)]
wide_result <- tidyr::pivot_wider(long_result, names_from = Name, values_from = Mvalue)
message("Data calculated/arranged for huprot arrays")
transposed_result <- as.data.frame(t(wide_result))
array <- paste0("Arr", sapply(basename(transposed_result[1,]), function(x) gsub("[^0-9]","", x)))
new_colname <- array
corrected_transposed_result <- transposed_result[-1,]
colnames(corrected_transposed_result) <- new_colname
numeric_df <- as.data.frame(lapply(corrected_transposed_result, as.numeric))
numeric_df <- as.data.frame(apply(numeric_df, 2, function(x) round(x, 2)))
rownames(numeric_df) <- rownames(corrected_transposed_result)
} else {
stop("Please define array type. Supports 'chambered', 'segmented', or 'huprot'")
}
if (nrow(numeric_df) == 0) {
warning("The resulting data frame is empty after processing.")
}
return(numeric_df)
}
orig_df <- make.df2(long_format, "huprot")
#' @export
#'
#' @examples
#' \dontrun{
#' # Example usage for chambered/segmented arrays
#' processed_data <- make.df(data = your_data, array_type = "chambered")
#'
#' # Example usage for huprot arrays
#' processed_data <- make.df(data = your_data, array_type = "huprot")
#' }
make.df2 <- function(data, array_type) {
# Convert data to data.table format
df <- data.table::setDT(data)
# Validate array_type parameter
if (!(array_type %in% c("chambered", "segmented", "huprot"))) {
stop("Invalid array_type. Please specify 'chambered', 'segmented', or 'huprot'.")
}
# Define required columns based on array type
required_columns <- if (array_type %in% c("chambered", "segmented")) {
c("array", "Block", "Name", "value")
} else {
c("array", "Name", "value")
}
# Check if the data contains the required columns
if (!all(required_columns %in% colnames(df))) {
stop(paste("Data must contain the following columns:", paste(required_columns, collapse = ", ")))
}
if (array_type == "chambered" || array_type == "segmented") {
long_result <- df[, .(Mvalue = mean(.SD$value, na.rm = TRUE)), by = .(array, Block, Name)]
wide_result <- tidyr::pivot_wider(long_result, names_from = Name, values_from = Mvalue)
message("Data calculated/arranged for chambered/segmented arrays")
transposed_result <- as.data.frame(t(wide_result))
file_names <- as.character(transposed_result[1, ])
array <- paste0("Arr", sapply(basename(file_names), function(x) gsub("[^0-9]", "", x)))
new_colname <- paste0(array, "-Block", transposed_result[2,])
corrected_transposed_result <- transposed_result[-c(1, 2), ]
colnames(corrected_transposed_result) <- new_colname
numeric_df <- as.data.frame(lapply(corrected_transposed_result, as.numeric))
numeric_df <- as.data.frame(apply(numeric_df, 2, function(x) round(x, 2)))
rownames(numeric_df) <- rownames(corrected_transposed_result)
} else if (array_type == "huprot") {
long_result <- df[, .(Mvalue = mean(.SD$value, na.rm = TRUE)), by = .(array, Name)]
wide_result <- tidyr::pivot_wider(long_result, names_from = Name, values_from = Mvalue)
message("Data calculated/arranged for huprot arrays")
transposed_result <- as.data.frame(t(wide_result))
file_names <- as.character(transposed_result[1, ])
array <- paste0("Arr", sapply(basename(file_names), function(x) gsub("[^0-9]", "", x)))
new_colname <- array
corrected_transposed_result <- transposed_result[-1, ]
colnames(corrected_transposed_result) <- new_colname
numeric_df <- as.data.frame(lapply(corrected_transposed_result, as.numeric))
numeric_df <- as.data.frame(apply(numeric_df, 2, function(x) round(x, 2)))
rownames(numeric_df) <- rownames(corrected_transposed_result)
} else {
stop("Please define array type. Supports 'chambered', 'segmented', or 'huprot'.")
}
if (nrow(numeric_df) == 0) {
warning("The resulting data frame is empty after processing.")
}
return(numeric_df)
}
orig_df <- make.df2(long_format, "huprot")
View(orig_df)
View(orig_df)
library(roxygen2)
library(devtools)
library(roxygen2)
library(devtools)
roxygenize()
build()
check()
library(devtools)
devtools::install_github("DrAhmetYalcinkaya/arrayrank")
library(arrayrank)
remove.packages("arrayrank")
library(devtools)
devtools::install_github("DrAhmetYalcinkaya/arrayrank")
detach("package:data.table", unload = TRUE)
devtools::install_github("DrAhmetYalcinkaya/arrayrank")
remove.packages("arrayrank")
library(devtools)
devtools::install_github("DrAhmetYalcinkaya/arrayrank")
library(arrayrank)
library(readxl)
# 1. collect gpr data and make dataset
files <- read.gpr()
bg_subbed <- subtract.bg(files)
long_format <- extraction(bg_subbed)
orig_df <- make.df(long_format, "huprot")
# 2. data correction
df <- replace.low(orig_df, offset = 10)
df_qnorm <- multinorm(df, method= "quantile")
# 3. storage and backup
df_qstore <- store.df(df_qnorm)
writexl::write_xlsx(df_qstore, "normed.xlsx")
# 4. read data from backup file
q_data <- readxl::read_xlsx(choose.files())
library(roxygen2)
library(devtools)
roxygenize()
build()
check()
?build()
roxygenize()
roxygenize()
build()
check()
library(arrayrank)
# 1. collect gpr data and make dataset
files <- read.gpr()
bg_subbed <- subtract.bg(files)
long_format <- extraction(bg_subbed)
orig_df <- make.df(long_format, "huprot")
# 2. data correction
df <- replace.low(orig_df, offset = 10)
View(df)
View(long_format)
df_qnorm <- multinorm(df, method= "quantile")
# 3. storage and backup
df_qstore <- store.df(df_qnorm)
View(df_qstore)
View(df_qnorm)
View(df_qstore)
